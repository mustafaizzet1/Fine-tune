# ğŸ§  Fine-tune: Hukuk Verileri Ãœzerine LLaMA TabanlÄ± Model EÄŸitimi

Bu proje, **Trendyol-LLM-7B-chat-v4.1.0** ve benzeri LLaMA tabanlÄ± bÃ¼yÃ¼k dil modellerini TÃ¼rkiye'deki **hukuk verileri** Ã¼zerine fine-tune etmeye odaklanÄ±r. Model eÄŸitimi, [Unsloth](https://github.com/unslothai/unsloth) kÃ¼tÃ¼phanesi kullanÄ±larak 4-bit quantization, PEFT (LoRA) ve Alpaca-style prompt formatlarÄ±yla gerÃ§ekleÅŸtirilmiÅŸtir.

---

## ğŸš€ Ã–zellikler

- âš–ï¸ TÃ¼rkiye'deki hukuki diyaloglarla eÄŸitilmiÅŸ Ã¶zel veri seti  
- ğŸ¦™ LLaMA-3 uyumlu 4-bit dÃ¼ÅŸÃ¼k bellekli model eÄŸitimi  
- ğŸ§© **Unsloth** ile optimize edilmiÅŸ dÃ¼ÅŸÃ¼k VRAM kullanÄ±mÄ±  
- ğŸ’¬ Alpaca tarzÄ± etkileÅŸimli prompt yapÄ±sÄ±  
- ğŸ” PEFT (LoRA) ile hÄ±zlÄ±, dÃ¼ÅŸÃ¼k kaynaklÄ± fine-tuning  
- ğŸ–¥ï¸ **T4 GPU** Ã¼zerinde bile sorunsuz Ã§alÄ±ÅŸÄ±r â€” yÃ¼ksek veri boyutlarÄ±na gerek olmadan bÃ¼yÃ¼k modelleri eÄŸitebilir

---

## ğŸ”§ Kurulum

```bash
pip install unsloth
pip install datasets trl bitsandbytes peft accelerate



ğŸ“ Veri FormatÄ±
EÄŸitim verisi .jsonl formatÄ±nda olup her satÄ±r ÅŸu yapÄ±ya sahiptir:

json
{
  "messages": [
    {"role": "system", "content": "Sistem mesajÄ±"},
    {"role": "user", "content": "KullanÄ±cÄ± mesajÄ±"},
    {"role": "assistant", "content": "Model cevabÄ±"}
  ]
}
